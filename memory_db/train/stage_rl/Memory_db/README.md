# Memory Database System for Reason-RFT

## ä½¿ç”¨æ–¹æ³•

- è¿™é‡Œ, æˆ‘ä»¬å…ˆç”¨update_db.pyä¸­çš„VLMInferenceManagerç±»æ¥å¤„ç†æ¨ç†å’Œæ•°æ®åº“æ›´æ–°ã€‚
- ç„¶å, æˆ‘ä»¬å°±å»ºç«‹å¥½äº†åˆæ­¥çš„æ•°æ®åº“. database.pyé‡Œé¢ get_llm_responses_sorted_by_average_score å¯ä»¥å°†é€‰å®šçš„æ ·æœ¬æŒ‰å¹³å‡åˆ†æ’åº, æˆ‘ä»¬å°±å¯ä»¥åšåç»­çš„æ“ä½œäº†, æ¯”å¦‚é€‰å–æ­£è´Ÿä¾‹å­å’Œæ·»åŠ reflexion(change_reflexion)

## æ¦‚è¿°

Memory Databaseæ˜¯Reason-RFTé¡¹ç›®ä¸­çš„ä¸€ä¸ªå…³é”®ç»„ä»¶ï¼Œä¸“é—¨ç”¨äºç®¡ç†å¼ºåŒ–å­¦ä¹ é˜¶æ®µçš„è®­ç»ƒæ•°æ®å’ŒVLMï¼ˆè§†è§‰è¯­è¨€æ¨¡å‹ï¼‰å“åº”ã€‚è¯¥ç³»ç»Ÿç»“åˆäº†ä¸¤ç§è®°å¿†æœºåˆ¶ï¼š**çŸ­æœŸè®°å¿†ï¼ˆSTMï¼‰**å’Œ**é•¿æœŸè®°å¿†ï¼ˆLTMï¼‰**ï¼Œä»¥åŠä¸€ä¸ªåŸºäºJSONçš„æ•°æ®åº“ï¼Œç”¨äºå­˜å‚¨å’Œç®¡ç†è®­ç»ƒæ ·æœ¬ã€æ¨¡å‹å“åº”åŠå…¶è¯„åˆ†ã€‚

## ç³»ç»Ÿæ¶æ„

```
Memory_db/
â”œâ”€â”€ database.py          # JSONæ•°æ®åº“æ ¸å¿ƒç»„ä»¶
â”œâ”€â”€ update_db.py         # VLMæ¨ç†å’Œæ•°æ®åº“æ›´æ–°ç®¡ç†å™¨
â”œâ”€â”€ vlm_agent.py         # VLMä»£ç†å’Œæç¤ºæ¨¡æ¿
â””â”€â”€ README.md           # æ–‡æ¡£è¯´æ˜ï¼ˆæœ¬æ–‡ä»¶ï¼‰
```

### å…³è”æ–‡ä»¶
- `../memory.py` - è®°å¿†ç®¡ç†å™¨ï¼Œå®ç°STM/LTMæœºåˆ¶

## æ ¸å¿ƒç»„ä»¶

### 1. JSONDatabase (`database.py`)

åŸºäºJSONæ–‡ä»¶çš„è½»é‡çº§æ•°æ®åº“ï¼Œä¸“é—¨ç”¨äºå­˜å‚¨è®­ç»ƒæ•°æ®å’ŒLLMå“åº”ã€‚

#### æ•°æ®ç»“æ„
```json
{
  "training_data": {
    "trance-001": {
      "id": "trance-001",
      "problem": "é—®é¢˜æè¿°",
      "answer": "æ­£ç¡®ç­”æ¡ˆ",
      "round": 1,
      "image": [...],
      "llm_answers_and_score": [
        {
          "ans": "æ¨¡å‹å“åº”",
          "reflexion": "åæ€è¿‡ç¨‹",
          "accuracy": 0.85,
          "format": 0.90,
          "reason": 0.75,
          "length": 0.80
        }
      ]
    }
  }
}
```

#### ä¸»è¦åŠŸèƒ½
- **æ•°æ®æ’å…¥/æ›´æ–°**: `insert_training_data()`
- **å“åº”æ·»åŠ **: `add_llm_response()`
- **æ•°æ®æ£€ç´¢**: `get_training_data()`, `get_all_training_data()`
- **æŒ‰è½®æ¬¡ç­›é€‰**: `get_training_data_by_round()`
- **æœç´¢åŠŸèƒ½**: `search_by_problem_text()`
- **ç»Ÿè®¡ä¿¡æ¯**: `get_statistics()`
- **æ’åºåŠŸèƒ½**: `get_llm_responses_sorted_by_average_score()`
- **æ•°æ®å¯¼å‡º**: `export_to_json()`

#### ç‰¹æ€§
- ğŸ”’ **çº¿ç¨‹å®‰å…¨**: ä½¿ç”¨é”æœºåˆ¶ç¡®ä¿å¹¶å‘å®‰å…¨
- ğŸ’¾ **åŸå­æ“ä½œ**: é€šè¿‡ä¸´æ—¶æ–‡ä»¶ç¡®ä¿æ•°æ®å®Œæ•´æ€§
- ğŸ“Š **è¯„åˆ†ç³»ç»Ÿ**: æ”¯æŒå¤šç»´åº¦è¯„åˆ†ï¼ˆå‡†ç¡®æ€§ã€æ ¼å¼ã€æ¨ç†ã€é•¿åº¦ï¼‰
- ğŸ” **é«˜æ•ˆæ£€ç´¢**: æ”¯æŒæŒ‰IDã€è½®æ¬¡ã€é—®é¢˜æ–‡æœ¬æ£€ç´¢

### 2. VLMInferenceManager (`update_db.py`)

ç®¡ç†VLMæ¨ç†è¿‡ç¨‹å’Œæ•°æ®åº“æ›´æ–°çš„æ ¸å¿ƒç®¡ç†å™¨ã€‚

#### æ ¸å¿ƒåŠŸèƒ½

##### å¤šæ¬¡æ¨ç†
```python
def multiple_inference(sample, image_dir, k=5, temperature=0.7, max_tokens=768)
```
- å¯¹åŒä¸€ä¸ªæ ·æœ¬æ‰§è¡Œkæ¬¡æ¨ç†
- æ”¯æŒæ¸©åº¦é‡‡æ ·æ§åˆ¶å¤šæ ·æ€§
- é”™è¯¯å¤„ç†å’Œæ¢å¤æœºåˆ¶

##### å¥–åŠ±è®¡ç®—
```python
def calculate_rewards(responses, ground_truth, current_step=0)
```
æ”¯æŒå››ç§å¥–åŠ±å‡½æ•°ï¼š
- **å‡†ç¡®æ€§å¥–åŠ±**: `accuracy_reward` / `math_accuracy_reward` / `func_accuracy_reward`
- **æ ¼å¼å¥–åŠ±**: `format_reward` / `caption_format_reward`
- **æ¨ç†å¥–åŠ±**: `reasoning_steps_reward`
- **é•¿åº¦å¥–åŠ±**: `len_reward`

##### æ‰¹å¤„ç†
```python
def process_batch(training_data_list, image_dir, k=5, ...)
```
- æ”¯æŒæ‰¹é‡å¤„ç†è®­ç»ƒæ ·æœ¬
- è¿›åº¦è·Ÿè¸ªå’Œé”™è¯¯æŠ¥å‘Š
- ç»“æœç»Ÿè®¡å’Œæ±‡æ€»

#### å·¥ä½œæµç¨‹
1. **æ•°æ®é¢„å¤„ç†**: åŠ è½½è®­ç»ƒæ•°æ®å’Œå›¾åƒ
2. **å¤šæ¬¡æ¨ç†**: ä½¿ç”¨VLMä»£ç†è¿›è¡Œkæ¬¡æ¨ç†
3. **å¥–åŠ±è®¡ç®—**: è®¡ç®—å¤šç»´åº¦å¥–åŠ±åˆ†æ•°
4. **æ•°æ®å­˜å‚¨**: å°†ç»“æœå­˜å‚¨åˆ°æ•°æ®åº“
5. **ç»“æœæ±‡æ€»**: ç”Ÿæˆå¤„ç†æŠ¥å‘Š

### 3. VLM Agent (`vlm_agent.py`)

æä¾›VLMæ¨ç†èƒ½åŠ›å’Œä»»åŠ¡ç‰¹å®šçš„æç¤ºæ¨¡æ¿ã€‚

#### æ”¯æŒçš„ä»»åŠ¡ç±»å‹
- **ç©ºé—´å˜æ¢**: `trance`, `trance-left`, `trance-right`
- **æ•°å­¦æ¨ç†**: `clevr-math`, `super-clevr`
- **å‡ ä½•æ¨ç†**: `geometry3k`, `geoqa`
- **ç»“æ„æ„ŸçŸ¥**: `structure-perception`

#### è¯„ä¼°ç±»å‹
- **CoT-SFT**: Chain-of-Thought with Supervised Fine-tuning
- **Caption-CoT**: Caption-based Chain-of-Thought

#### æç¤ºæ¨¡æ¿ç¤ºä¾‹
```python
COT_TRANCE_QUESTION_PROMPT = '''
Your need to complete the spatial visual reasoning task...
Output the thinking process in <think> </think> and final answer in <answer> </answer> tags.
'''
```

### 4. MemoryManager (`../memory.py`)

å®ç°åŒé‡è®°å¿†æœºåˆ¶çš„æ ¸å¿ƒç»„ä»¶ã€‚

#### çŸ­æœŸè®°å¿†ï¼ˆSTMï¼‰
- ä½¿ç”¨`deque`å­˜å‚¨æœ€è¿‘å‡ æ‰¹çš„åé¦ˆæ–‡æœ¬
- ç›´æ¥æ‹¼æ¥ï¼Œæ— éœ€æ£€ç´¢
- å¿«é€Ÿè®¿é—®æœ€æ–°åé¦ˆ

#### é•¿æœŸè®°å¿†ï¼ˆLTMï¼‰
- å­˜å‚¨"ç»éªŒ"ï¼ˆæ–‡æœ¬+åµŒå…¥å‘é‡ï¼‰
- åŸºäºä½™å¼¦ç›¸ä¼¼åº¦çš„è¯­ä¹‰æ£€ç´¢
- æ”¯æŒç»éªŒç´¯ç§¯å’Œé•¿æœŸå­¦ä¹ 

#### ä¸»è¦æ–¹æ³•
```python
# STMæ“ä½œ
add_stm_feedback(feedback_text)
get_stm_context()

# LTMæ“ä½œ  
add_ltm_experience(experience_text, meta)
retrieve_ltm(query, k=3)
get_ltm_context(query, k=3)

# ç»Ÿä¸€æ¥å£
build_memory_prefix(query, k=3)
```

## ä½¿ç”¨æŒ‡å—

### 1. åŸºç¡€æ•°æ®åº“æ“ä½œ

```python
from database import JSONDatabase

# åˆå§‹åŒ–æ•°æ®åº“
db = JSONDatabase("my_memory_db.json")

# æ’å…¥è®­ç»ƒæ•°æ®
training_data = {
    'id': 'sample-001',
    'problem': 'é—®é¢˜æè¿°',
    'answer': 'æ­£ç¡®ç­”æ¡ˆ',
    'round': 1,
    'image': [{'path': 'image1.png', 'type': 'Spatial-Transformation'}]
}
db.insert_training_data(training_data)

# æ·»åŠ LLMå“åº”
scores = {'accuracy': 0.85, 'format': 0.90, 'reason': 0.75, 'length': 0.80}
db.add_llm_response('sample-001', 'LLMçš„å“åº”', scores)

# è·å–æ•°æ®
data = db.get_training_data('sample-001')
stats = db.get_statistics()
```

### 2. VLMæ¨ç†å’Œæ›´æ–°

```python
from update_db import VLMInferenceManager

# åˆå§‹åŒ–ç®¡ç†å™¨
manager = VLMInferenceManager(
    model_name_or_path="/path/to/model",
    db_path="memory_db.json",
    task_name="trance",
    eval_type="cot-sft"
)

# å¤„ç†å•ä¸ªæ ·æœ¬
success = manager.process_and_store(
    training_data=sample_data,
    image_dir="/path/to/images",
    k=5,  # æ‰§è¡Œ5æ¬¡æ¨ç†
    temperature=0.7,
    round=1
)

# æ‰¹å¤„ç†
results = manager.process_batch(
    training_data_list=samples,
    image_dir="/path/to/images",
    k=5,
    round=2
)
```

### 3. å‘½ä»¤è¡Œä½¿ç”¨

```bash
# å¤„ç†JSONæ–‡ä»¶ä¸­çš„è®­ç»ƒæ•°æ®
python update_db.py \
    --model_path /path/to/qwen_model \
    --image_dir /path/to/images \
    --data_json training_data.json \
    --k 5 \
    --temperature 0.7 \
    --round 2

# ä½¿ç”¨æµ‹è¯•æ ·æœ¬
python update_db.py \
    --model_path /path/to/qwen_model \
    --image_dir /path/to/images \
    --test_sample \
    --round 1
```

### 4. è®°å¿†ç³»ç»Ÿé›†æˆ

```python
from memory import MemoryManager

# åˆå§‹åŒ–è®°å¿†ç®¡ç†å™¨
memory = MemoryManager(stm_max_batches=3, ltm_max_items=1000)
memory.set_embedder(tokenizer, model, device="cuda")

# æ·»åŠ åé¦ˆå’Œç»éªŒ
memory.add_stm_feedback("æœ€è¿‘çš„è®­ç»ƒåé¦ˆ")
memory.add_ltm_experience("é‡è¦çš„è®­ç»ƒç»éªŒ", {"type": "error_pattern"})

# æ„å»ºè®°å¿†å‰ç¼€
memory_prefix = memory.build_memory_prefix("å½“å‰æŸ¥è¯¢", k=3)
```

## é…ç½®é€‰é¡¹

### æ•°æ®åº“é…ç½®
- `db_path`: æ•°æ®åº“æ–‡ä»¶è·¯å¾„
- `max_batches`: STMæœ€å¤§æ‰¹æ¬¡æ•°
- `max_items`: LTMæœ€å¤§é¡¹ç›®æ•°

### æ¨ç†é…ç½®
- `k`: æ¯ä¸ªæ ·æœ¬çš„æ¨ç†æ¬¡æ•°
- `temperature`: é‡‡æ ·æ¸©åº¦
- `max_tokens`: æœ€å¤§tokenæ•°
- `max_image_num`: æœ€å¤§å›¾åƒæ•°é‡

### ä»»åŠ¡é…ç½®
- `task_name`: ä»»åŠ¡ç±»å‹ (`trance`, `clevr-math`, ç­‰)
- `eval_type`: è¯„ä¼°ç±»å‹ (`cot-sft`, `caption-cot`)

## è¯„åˆ†ç³»ç»Ÿ

ç³»ç»Ÿæ”¯æŒå››ä¸ªç»´åº¦çš„è¯„åˆ†ï¼š

1. **å‡†ç¡®æ€§ (Accuracy)**: ç­”æ¡ˆçš„æ­£ç¡®æ€§
2. **æ ¼å¼ (Format)**: è¾“å‡ºæ ¼å¼çš„è§„èŒƒæ€§
3. **æ¨ç† (Reason)**: æ¨ç†è¿‡ç¨‹çš„è´¨é‡
4. **é•¿åº¦ (Length)**: å›ç­”é•¿åº¦çš„é€‚å½“æ€§

æ¯ä¸ªç»´åº¦çš„åˆ†æ•°èŒƒå›´ä¸º0.0-1.0ï¼Œç³»ç»Ÿè‡ªåŠ¨è®¡ç®—å¹³å‡åˆ†æ•°å¹¶æ”¯æŒæŒ‰åˆ†æ•°æ’åºã€‚

## ç»Ÿè®¡ä¿¡æ¯

æ•°æ®åº“æä¾›ä¸°å¯Œçš„ç»Ÿè®¡ä¿¡æ¯ï¼š

```python
stats = db.get_statistics()
# è¿”å›:
# {
#   'total_training_entries': 100,
#   'total_llm_responses': 500,
#   'round_distribution': {1: 60, 2: 40},
#   'average_scores': {
#     'avg_accuracy': 0.75,
#     'avg_format': 0.85,
#     'avg_reason': 0.70,
#     'avg_length': 0.80
#   }
# }
```

## æ€§èƒ½ä¼˜åŒ–

### å†…å­˜ç®¡ç†
- LTMå‘é‡å­˜å‚¨åœ¨CPUä¸ŠèŠ‚çœæ˜¾å­˜
- æ”¯æŒå‘é‡L2å½’ä¸€åŒ–åŠ é€Ÿç›¸ä¼¼åº¦è®¡ç®—
- dequeæä¾›é«˜æ•ˆçš„FIFOæ“ä½œ

### å¹¶å‘å®‰å…¨
- æ•°æ®åº“æ“ä½œä½¿ç”¨çº¿ç¨‹é”
- åŸå­æ–‡ä»¶å†™å…¥é¿å…æ•°æ®æŸå
- å¼‚å¸¸å¤„ç†ç¡®ä¿ç³»ç»Ÿç¨³å®šæ€§

### æ‰©å±•æ€§
- æ¨¡å—åŒ–è®¾è®¡æ”¯æŒæ–°ä»»åŠ¡ç±»å‹
- æ’ä»¶å¼å¥–åŠ±å‡½æ•°æ¶æ„
- çµæ´»çš„é…ç½®ç³»ç»Ÿ

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **æ•°æ®åº“æŸå**
   - ç³»ç»Ÿä¼šè‡ªåŠ¨åˆ›å»ºå¤‡ä»½æ–‡ä»¶
   - æ”¯æŒä»æŸåçš„JSONæ¢å¤

2. **å†…å­˜ä¸è¶³**
   - è°ƒæ•´LTMæœ€å¤§é¡¹ç›®æ•°
   - ä½¿ç”¨CPUå­˜å‚¨å‘é‡

3. **æ¨ç†å¤±è´¥**
   - æ£€æŸ¥æ¨¡å‹è·¯å¾„å’Œæƒé™
   - éªŒè¯å›¾åƒæ–‡ä»¶å®Œæ•´æ€§

### æ—¥å¿—å’Œè°ƒè¯•
- è¯¦ç»†çš„è¿›åº¦è·Ÿè¸ª
- é”™è¯¯ä¿¡æ¯å’Œå †æ ˆè·Ÿè¸ª
- æ€§èƒ½ç»Ÿè®¡å’Œæ—¶é—´æµ‹é‡

## æ‰©å±•å¼€å‘

### æ·»åŠ æ–°ä»»åŠ¡ç±»å‹
1. åœ¨`vlm_agent.py`ä¸­æ·»åŠ æç¤ºæ¨¡æ¿
2. åœ¨`update_db.py`ä¸­é…ç½®å¥–åŠ±å‡½æ•°
3. æ›´æ–°ä»»åŠ¡æ˜ å°„å…³ç³»

### è‡ªå®šä¹‰å¥–åŠ±å‡½æ•°
```python
def custom_reward_function(responses, solutions=None, step=0):
    """è‡ªå®šä¹‰å¥–åŠ±å‡½æ•°"""
    scores = []
    for response in responses:
        # å®ç°è‡ªå®šä¹‰è¯„åˆ†é€»è¾‘
        score = calculate_custom_score(response)
        scores.append(score)
    return scores
```

### æ•°æ®åº“æ‰©å±•
- æ”¯æŒæ–°çš„æ•°æ®å­—æ®µ
- æ·»åŠ ç´¢å¼•å’ŒæŸ¥è¯¢ä¼˜åŒ–
- å®ç°æ•°æ®è¿ç§»æœºåˆ¶

## è®¸å¯è¯

æœ¬é¡¹ç›®éµå¾ªç›¸åº”çš„å¼€æºè®¸å¯è¯ã€‚è¯¦ç»†ä¿¡æ¯è¯·å‚è€ƒé¡¹ç›®æ ¹ç›®å½•çš„LICENSEæ–‡ä»¶ã€‚

## è´¡çŒ®æŒ‡å—

æ¬¢è¿æäº¤Issueå’ŒPull Requestæ¥æ”¹è¿›è¿™ä¸ªç³»ç»Ÿã€‚è¯·ç¡®ä¿ï¼š
- ä»£ç ç¬¦åˆé¡¹ç›®è§„èŒƒ
- åŒ…å«é€‚å½“çš„æµ‹è¯•
- æ›´æ–°ç›¸å…³æ–‡æ¡£

## è”ç³»ä¿¡æ¯

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·é€šè¿‡é¡¹ç›®çš„GitHub Issuesè”ç³»æˆ‘ä»¬ã€‚
